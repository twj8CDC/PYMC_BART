{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sksurv as sks\n",
    "import sksurv.preprocessing\n",
    "import sksurv.metrics\n",
    "import sksurv.datasets\n",
    "import sksurv.linear_model\n",
    "import sksurv.ensemble\n",
    "\n",
    "from pathlib import Path\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as skl\n",
    "import scipy.stats as sp\n",
    "\n",
    "import pymc as pm\n",
    "import pymc_bart as pmb\n",
    "import pandas as pd\n",
    "\n",
    "import importlib\n",
    "import mlflow as ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ioff()\n",
    "np.random.seed(99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simsurv_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "Simulations of the cox proportional and non proportional survial models. \n",
    "Validation of bart pymc against cph model, rsf model.\n",
    "\n",
    "Validation metrics:\n",
    "    2 bool\n",
    "    5 bool\n",
    "    2 bool + 1 linear\n",
    "    complex combination\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_surv(N=100, \n",
    "            T=100, \n",
    "            x_vars = 1, \n",
    "            lambda_f=None, \n",
    "            a=2, \n",
    "            alpha_f = None, \n",
    "            seed=999, \n",
    "            cens_ind = True,\n",
    "            cens_scale = 20,\n",
    "            err_ind = False):\n",
    "    # np.random.seed(seed)\n",
    "\n",
    "    x_mat = np.zeros((N, x_vars))\n",
    "    for x in np.arange(x_vars):\n",
    "        x1 = sp.bernoulli.rvs(.5, size = N)\n",
    "        x_mat[:,x] = x1\n",
    "    # calculate lambda\n",
    "    \n",
    "    # set lambda\n",
    "    if lambda_f is None:\n",
    "        lmbda = np.exp(2 + 0.3*(x_mat[:,0] + x_mat[:,1]) + x_mat[:,2])\n",
    "    else:\n",
    "        lmbda = eval(lambda_f)\n",
    "    \n",
    "    # set alpha if specified\n",
    "    if alpha_f is None:\n",
    "        a = np.repeat(a, N)\n",
    "    else:\n",
    "        a = eval(alpha_f)\n",
    "\n",
    "    # add error\n",
    "    if err_ind:\n",
    "        error = sp.norm.rvs(0, .5, size = N)\n",
    "        lmbda=lmbda + error\n",
    "\n",
    "    # get time series\n",
    "    t = np.linspace(0,T, T)\n",
    "\n",
    "    # calculate survival and event times\n",
    "    sv_mat = np.zeros((N, t.shape[0]))\n",
    "    tlat = np.zeros(N)\n",
    "    for idx, l in enumerate(lmbda):\n",
    "        sv = np.exp(-1 * np.power((t/l), a[idx]))\n",
    "        sv_mat[idx,:] = sv\n",
    "        \n",
    "        # generate event times \n",
    "        unif = np.random.uniform(size=1)\n",
    "        ev = lmbda[idx] * np.power((-1 * np.log(unif)), 1/a[idx])\n",
    "        tlat[idx] = ev\n",
    "\n",
    "    if cens_ind:\n",
    "        # censor\n",
    "        cens = np.ceil(np.random.exponential(size = N, scale = cens_scale))\n",
    "\n",
    "        # min cen and surv event\n",
    "        t_event  = np.minimum(cens, np.ceil(tlat))\n",
    "        status = (tlat <= cens) * 1\n",
    "    else:\n",
    "        cens=np.zeros(N)\n",
    "        t_event = np.ceil(tlat)\n",
    "        status = np.ones(N)\n",
    "\n",
    "        \n",
    "\n",
    "    return sv_mat, x_mat, lmbda, a, tlat, cens, t_event, status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_x_info(x_mat):\n",
    "#     x_comb_unique = np.unique(x_mat, axis=0)\n",
    "#     return x_comb_unique\n",
    "\n",
    "def get_x_info(x_mat):\n",
    "    x = np.unique(x_mat, axis=0, return_index=True, return_counts=True)\n",
    "    x_out, x_idx, x_cnt = x[0], x[1], x[2]\n",
    "    return x_out, x_idx, x_cnt\n",
    "\n",
    "\n",
    "def get_status_perc(status):\n",
    "    out = status.sum()/status.shape[0]\n",
    "    cens = 1-out\n",
    "    return out, cens\n",
    "\n",
    "def get_event_time_metric(t_event):\n",
    "    t_mean = t_event.mean()\n",
    "    t_max = t_event.max()\n",
    "    return t_mean, t_max\n",
    "\n",
    "def get_train_matrix(x_mat, t_event, status):\n",
    "    et = pd.DataFrame({\"status\": status, \"time\":t_event})\n",
    "    train = pd.concat([et, pd.DataFrame(x_mat)],axis=1)\n",
    "    return train\n",
    "\n",
    "def get_y_sklearn(status, t_event):\n",
    "    y = np.array(list(zip(np.array(status, dtype=\"bool\"), t_event)), dtype=[(\"Status\",\"?\"),(\"Survival_in_days\", \"<f8\")])\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Function\n",
    "def plot_sv(x_mat, sv_mat, t, title=\"TITLE\", save=False, dir=\".\", show=False):\n",
    "    dist_x, dist_idx = np.unique(x_mat, axis=0, return_index=True)\n",
    "\n",
    "    # print(tt)\n",
    "    try:\n",
    "        fig = plt.figure()\n",
    "        if sv_mat.shape[0] != dist_idx.shape[0]:\n",
    "            for idx, i in enumerate(sv_mat[dist_idx]):\n",
    "                plt.step(np.arange(t), i, label = str(dist_x[idx]))\n",
    "                plt.legend()\n",
    "                plt.title(title)\n",
    "        else:\n",
    "            for idx, i in enumerate(sv_mat):\n",
    "                plt.step(np.arange(t), i, label = str(dist_x[idx]))\n",
    "                plt.legend()\n",
    "                plt.title(title)\n",
    "        if show:\n",
    "            plt.show()\n",
    "        if save:\n",
    "            plt.savefig(f\"{dir}/{title}.png\")\n",
    "    finally:\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def surv_pre_train(data_x_n, data_y, X_TIME=True):\n",
    "    # set up times\n",
    "    # t_sort = np.append([0], np.unique(data_y[\"Survival_in_days\"]))\n",
    "    t_sort = np.unique(data_y[\"Survival_in_days\"])\n",
    "    t_ind = np.arange(0,t_sort.shape[0])\n",
    "    t_dict = dict(zip(t_sort, t_ind))\n",
    "\n",
    "    # set up delta\n",
    "    delta = np.array(data_y[\"Status\"], dtype = \"int\")\n",
    "    \n",
    "    t_out = []\n",
    "    pat_x_out = []\n",
    "    delta_out = []\n",
    "    for idx, t in enumerate(data_y[\"Survival_in_days\"]):\n",
    "        # get the pat_time and use to get the array of times for the patient\n",
    "        p_t_ind = t_dict[t]\n",
    "        p_t_set = t_sort[0:p_t_ind+1]\n",
    "        t_out.append(p_t_set)\n",
    "        \n",
    "        size = p_t_set.shape[0]\n",
    "        # get patient array\n",
    "        pat_x = np.tile(data_x_n.iloc[idx].to_numpy(), (size, 1))\n",
    "        pat_x_out.append(pat_x)\n",
    "\n",
    "        # get delta\n",
    "        pat_delta = delta[idx]\n",
    "        delta_set = np.zeros(shape=size, dtype=int)\n",
    "        delta_set[-1] = pat_delta\n",
    "        delta_out.append(delta_set)\n",
    "    \n",
    "    \n",
    "    t_out, delta_out, pat_x_out = np.concatenate(t_out), np.concatenate(delta_out), np.concatenate(pat_x_out)\n",
    "    if X_TIME:\n",
    "        pat_x_out = np.array([np.concatenate([np.array([t_out[idx]]), i]) for idx, i in enumerate(pat_x_out)])\n",
    "    return t_out, delta_out, pat_x_out\n",
    "\n",
    "def surv_pre_test(data_x_n, data_y, X_TIME=True):\n",
    "    # t_sort = np.append([0], np.unique(data_y[\"Survival_in_days\"]))\n",
    "    t_sort = np.unique(data_y[\"Survival_in_days\"])\n",
    "    t_out = []\n",
    "    pat_x_out = []\n",
    "    for idx, t in enumerate(data_y[\"Survival_in_days\"]):\n",
    "        # get the pat_time and use to get the array of times for the patient\n",
    "        p_t_set = t_sort\n",
    "        t_out.append(p_t_set)\n",
    "        \n",
    "        size = p_t_set.shape[0]\n",
    "        # get patient array\n",
    "        pat_x = np.tile(data_x_n.iloc[idx].to_numpy(), (size, 1))\n",
    "        pat_x_out.append(pat_x)\n",
    "    \n",
    "    t_out, pat_x_out = np.concatenate(t_out),  np.concatenate(pat_x_out)\n",
    "    if X_TIME:\n",
    "        pat_x_out = np.array([np.concatenate([np.array([t_out[idx]]), i]) for idx, i in enumerate(pat_x_out)])\n",
    "    return t_out, pat_x_out\n",
    "\n",
    "def get_bart_test(x_out, T):\n",
    "    d1 = np.arange(T + 1)\n",
    "    d2 = np.arange(x_out.shape[1])\n",
    "    \n",
    "    out = np.stack(np.array(np.meshgrid(d1, d2, d2)),-1).reshape(-1, d2.shape[0] + 1)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set experiment\n",
    "    # - each simulation parms is a new experiment\n",
    "\n",
    "# Simulation loop\n",
    "    # Creat run\n",
    "        # Simulate data\n",
    "        # log param alpha, lambda\n",
    "        # log param N\n",
    "        # log param T (of probabilites generated)\n",
    "        # log param x_info\n",
    "        # log param cen percent calculated\n",
    "        # log param status event calculated\n",
    "        # log param t_event mean\n",
    "        # log param t_event max\n",
    "        # log artif train dataset\n",
    "        # log artif plot curves\n",
    "\n",
    "        # model cph\n",
    "        # log metri coeff\n",
    "        # log metri exp(coef)\n",
    "        # log artif plot curves\n",
    "        # log model cph\n",
    "        \n",
    "        #  model rsf\n",
    "        # log artif plot curves\n",
    "        # log model resf\n",
    "\n",
    "        # tranform data long-form\n",
    "        # model bart\n",
    "        # transform to survival\n",
    "        # log artif plot curves\n",
    "        # log model bart\n",
    "\n",
    "        # get metrics rmse, bias\n",
    "        # log metri cph_rmse\n",
    "        # log metri cph_bias\n",
    "        # log metri rsf_rmse\n",
    "        # log metri rsf_bias\n",
    "        # log metri bart_rmse\n",
    "        # log metri bart_bias\n",
    "    \n",
    "    # End run\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.create_experiment(name = \"test_sim\")\n",
    "# Set experiment\n",
    "    # - each simulation parms is a new experiment\n",
    "\n",
    "# Simulation loop\n",
    "\n",
    "    # Creat run\n",
    "with ml.start_run() as run:\n",
    "    OUTPUTS = \"output\"\n",
    "    ALPHA = 3\n",
    "    LAMBDA = \"np.exp(2 + 0.3*(x_mat[:,0] + x_mat[:,1]))\"\n",
    "    N = 100\n",
    "    T = 30\n",
    "    X_VARS = 2\n",
    "    CENS_SCALE = 60\n",
    "    # Simulate data\n",
    "    sv_mat, x_mat, lmbda, a, tlat, cens, t_event, status = sim_surv(N=N, \n",
    "                    T=T,\n",
    "                    x_vars=X_VARS,\n",
    "                    a = ALPHA,\n",
    "                    lambda_f = LAMBDA,\n",
    "                    cens_scale=CENS_SCALE,\n",
    "                    err_ind = False)\n",
    "\n",
    "    # log param alpha\n",
    "    ml.log_param(\"alpha\", ALPHA)\n",
    "    # log param labmda\n",
    "    ml.log_param(\"lambda\", LAMBDA)\n",
    "    # log param N\n",
    "    ml.log_param(\"N\", N)\n",
    "    # log param T (# timepoint probabilites generated)\n",
    "    ml.log_param(\"T\", T)\n",
    "    # log param X_VARS\n",
    "    ml.log_param(\"X_VARS\", X_VARS)\n",
    "    # log parm CENS_SCALE\n",
    "    ml.log_param(\"CENS_SCALE\", CENS_SCALE)\n",
    "    \n",
    "    \n",
    "    # log param x_info\n",
    "    x_out, x_idx, x_cnt = get_x_info(x_mat)\n",
    "    ml.log_param(\"X_INFO\", str(list(zip(x_out, x_cnt))))\n",
    "\n",
    "    # log metric cen percent calculated\n",
    "    # log metric status event calculated\n",
    "    event_calc, cens_calc = get_status_perc(status)\n",
    "    ml.log_metric(\"EVENT_PERC\", event_calc)\n",
    "    ml.log_metric(\"CENS_PERC\", cens_calc)\n",
    "\n",
    "    # log metric t_event mean\n",
    "    # log metric t_event max\n",
    "    t_mean, t_max = get_event_time_metric(t_event)\n",
    "    ml.log_metric(\"T_EVENT_MEAN\", t_mean)\n",
    "    ml.log_metric(\"T_EVENT_MAX\", t_max)\n",
    "    \n",
    "    # log artif train dataset\n",
    "    train = get_train_matrix(x_mat, t_event, status)\n",
    "    ml.log_artifact(\"TRAIN\", train)\n",
    "    \n",
    "    # log artif plot curves\n",
    "    title = \"actual_survival\"\n",
    "    plot_sv(x_mat, sv_mat, T, title=title, save = True, dir=\"output\")\n",
    "    ml.log_artifact(f\"output/{title}.png\")\n",
    "    \n",
    "\n",
    "    # get sklearn components\n",
    "    y_sk = get_y_sklearn(status, t_event)\n",
    "    x_sk = train.iloc[:,2:]\n",
    "\n",
    "    # model cph\n",
    "    cph = sksurv.linear_model.CoxPHSurvivalAnalysis()\n",
    "    cph.fit(x_sk, y_sk)\n",
    "    # log metri coeff\n",
    "    ml.log_metric(\"cph_coef\", cph.coef_)\n",
    "    # log metri exp(coef)\n",
    "    ml.log_metric(\"cph_exp_coef\", np.exp(cph.coef_))\n",
    "    # predic cph\n",
    "    cph_surv = cph.predict_survival_function(pd.DataFrame(x_out))\n",
    "    cph_sv_val = [sf(np.arange(T)) for sf in cph_surv]\n",
    "    # log artif plot curves\n",
    "    title = \"cph_surv_pred\"\n",
    "    plot_sv(x_mat, cph_sv_val, T, title = title, save=True, dir=\"outputs\")\n",
    "    ml.log_artifact(f\"outputs/{title}.png\")\n",
    "    # log model cph\n",
    "    # idk how to do\n",
    "    \n",
    "    #  model rsf\n",
    "    rsf = sksurv.ensemble.RandomSurvivalForest(\n",
    "        n_estimators=1000, min_samples_split=10, min_samples_leaf=15, n_jobs=-1, random_state=20\n",
    "    )\n",
    "    rsf.fit(x_sk, y_sk)\n",
    "    # predict rsf\n",
    "    rsf_surv = rsf.predict_survival_function(pd.DataFrame(x_out))\n",
    "    rsf_sv_val = [sf(np.arange(T)) for sf in rsf_surv]\n",
    "    # log artif plot curves\n",
    "    title = \"rsf_surv_pred\"\n",
    "    plot_sv(x_mat, rsf_sv_val, T, title=title, save=True, dir=\"outputs\")\n",
    "    ml.log_artifact(f\"outputs/{title}.png\")\n",
    "    # log model resf\n",
    "\n",
    "    # tranform data long-form\n",
    "    b_tr_t, b_tr_delta, b_tr_x = surv_pre_train(x_sk, y_sk)\n",
    "    # b_te_t, b_te_x = surv_pre_test(x_sk, y_sk)\n",
    "    b_te_x = get_bart_test(x_out, T)\n",
    "    off = sp.norm.ppf(np.mean(b_tr_delta))\n",
    "    # model bart\n",
    "    with pm.Model() as bart:\n",
    "        x_data = pm.MutableData(\"x\", b_tr_x)\n",
    "        f = pmb.BART(\"f\", X=x_data, y=b_tr_delta, m=50)\n",
    "        z = pm.Deterministic(\"z\", f + off)\n",
    "        mu = pm.Deterministic(\"mu\", pm.math.invprobit(z))\n",
    "        y_pred = pm.Bernoulli(\"y_pred\")\n",
    "        \n",
    "\n",
    "    # transform to survival\n",
    "    # log artif plot curves\n",
    "    # log model bart\n",
    "\n",
    "    # get metrics rmse, bias\n",
    "    # log metri cph_rmse\n",
    "    # log metri cph_bias\n",
    "    # log metri rsf_rmse\n",
    "    # log metri rsf_bias\n",
    "    # log metri bart_rmse\n",
    "    # log metri bart_bias\n",
    "\n",
    "# End run (defaults when using with/ block)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
